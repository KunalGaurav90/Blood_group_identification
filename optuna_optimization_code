#install optuna
!pip install optuna
import optuna

# 1. Define the function you want to minimize (or maximize)
def objective(trial):
    # Suggest a value for 'x' between -10 and 10
    x = trial.suggest_float("x", -10, 10)
    # Return the result of the function
    return (x - 2) ** 2

# 2. Create and run the study
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=100)

print(f"Best parameter: {study.best_params}")
print(f"Best value: {study.best_value}")

# Run this cell first to install dependencies
!pip install --upgrade optuna
!pip install optuna-integration[tfkeras]

# Then run the rest of the code

from optuna.integration import TFKerasPruningCallback

# Install the integration package first
!pip install optuna-integration[tfkeras]

# Then import
from optuna_integration.tfkeras import TFKerasPruningCallback

# ============================================================================
# PART 1: INSTALL OPTUNA AND INTEGRATION
# ============================================================================
!pip install optuna
!pip install optuna-integration[tfkeras]

import optuna
from optuna_integration.tfkeras import TFKerasPruningCallback  # ✅ FIXED IMPORT
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np

# ============================================================================
# PART 2: DEFINE OPTUNA OBJECTIVE FUNCTION FOR SIMPLE CNN
# ============================================================================

def create_optimized_simple_cnn(trial, input_shape, num_classes):
    """
    Creates a Simple CNN model with Optuna-tuned hyperparameters.
    """
    n_conv_layers = trial.suggest_int('n_conv_layers', 2, 4)
    dropout_rate = trial.suggest_float('dropout', 0.3, 0.7)
    dense_units = trial.suggest_int('dense_units', 64, 256, step=32)
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)

    input_tensor = Input(shape=input_shape)
    x = input_tensor

    for i in range(n_conv_layers):
        filters = trial.suggest_int(f'filters_layer_{i}', 32, 128, step=32)
        x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)
        x = BatchNormalization()(x)
        x = MaxPooling2D((2, 2))(x)

    x = Flatten()(x)
    x = Dense(dense_units, activation='relu')(x)
    x = Dropout(dropout_rate)(x)
    output_tensor = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=input_tensor, outputs=output_tensor)

    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer,
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    return model


def objective_simple_cnn(trial):
    """
    Optuna objective function for Simple CNN optimization.
    """
    model = create_optimized_simple_cnn(trial, input_shape_cnn, num_classes)

    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])

    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
    pruning_callback = TFKerasPruningCallback(trial, 'val_accuracy')  # ✅ NOW WORKS

    history = model.fit(
        X_train, y_train,
        epochs=15,
        batch_size=batch_size,
        validation_data=(X_val, y_val),
        callbacks=[early_stopping, pruning_callback],
        verbose=0
    )

    val_accuracy = max(history.history['val_accuracy'])

    return val_accuracy


# ============================================================================
# PART 3: RUN OPTUNA OPTIMIZATION
# ============================================================================

print("Starting Optuna hyperparameter optimization for Simple CNN...")
study_simple_cnn = optuna.create_study(
    direction='maximize',
    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3)
)

study_simple_cnn.optimize(objective_simple_cnn, n_trials=30, timeout=3600)

print("\n" + "="*80)
print("OPTUNA OPTIMIZATION RESULTS - SIMPLE CNN")
print("="*80)
print(f"Best Trial: {study_simple_cnn.best_trial.number}")
print(f"Best Validation Accuracy: {study_simple_cnn.best_value:.4f}")
print(f"\nBest Hyperparameters:")
for key, value in study_simple_cnn.best_params.items():
    print(f"  {key}: {value}")
print("="*80)


# ============================================================================
# PART 4: BUILD FINAL OPTIMIZED MODEL
# ============================================================================

print("\nTraining final Simple CNN with best hyperparameters...")

best_simple_cnn_model = create_optimized_simple_cnn(
    study_simple_cnn.best_trial,
    input_shape_cnn,
    num_classes
)

best_batch_size = study_simple_cnn.best_params['batch_size']

history_optimized_cnn = best_simple_cnn_model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=best_batch_size,
    validation_data=(X_val, y_val),
    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],
    verbose=1
)

print("\nOptimized Simple CNN training complete!")


# ============================================================================
# ALTERNATIVE: VERSION WITHOUT PRUNING (IF INSTALLATION FAILS)
# ============================================================================

# If you still have issues, use this version WITHOUT pruning callback:

def objective_simple_cnn_no_pruning(trial):
    """
    Optuna objective WITHOUT pruning (simpler, no extra dependencies).
    """
    model = create_optimized_simple_cnn(trial, input_shape_cnn, num_classes)

    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])

    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

    # NO pruning callback - just train normally
    history = model.fit(
        X_train, y_train,
        epochs=10,  # Reduced epochs for faster trials
        batch_size=batch_size,
        validation_data=(X_val, y_val),
        callbacks=[early_stopping],
        verbose=0
    )

    val_accuracy = max(history.history['val_accuracy'])

    return val_accuracy


# Run optimization without pruning
study_simple_cnn_no_pruning = optuna.create_study(direction='maximize')
study_simple_cnn_no_pruning.optimize(objective_simple_cnn_no_pruning, n_trials=3)

print(f"\nBest Accuracy (No Pruning): {study_simple_cnn_no_pruning.best_value:.4f}")
print(f"Best Parameters: {study_simple_cnn_no_pruning.best_params}")

